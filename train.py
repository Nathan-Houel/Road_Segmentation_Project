import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from model import UNET
from my_dataset import RoadDataset
from tqdm import tqdm
import matplotlib.pyplot as plt


# --- HYPERPARAM√àTRES ---
LEARNING_RATE = 1e-4  # Vitesse √† laquelle le mod√®le modifie ses poids (trop grand = instable, trop petit = lent)       
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
BATCH_SIZE = 4  # Nombre d'images trait√©es en m√™me temps (si ta m√©moire sature, baisse √† 2 ou 1)              
NUM_EPOCHS = 10  # Nombre de fois que le mod√®le va voir l'ensemble du dataset           
NUM_WORKERS = 2  # Nombre de processeurs utilis√©s pour charger les donn√©es           
IMAGE_HEIGHT = 256
IMAGE_WIDTH = 256
TRAIN_IMG_DIR = "dataset/images" 
TRAIN_MASK_DIR = "dataset/masks"


if __name__ == "__main__":
    # Instancie le Dataset
    Dataset = RoadDataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR)

    # Cr√©er le DataLoader
    train_loader = DataLoader(Dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)

    # Le mod√®le 
    model = UNET(in_channels=3, out_channels=1).to(DEVICE)

    # La Loss (Sigmoid + Binary Cross Entropy)
    loss_fn = nn.BCEWithLogitsLoss()

    # L'Optimiseur
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    loss_history = []

    # Boucle d'entra√Ænement
    print("D√©but de l'entra√Ænement ! üöÄ")
    for epoch in range(NUM_EPOCHS):
        loop = tqdm(train_loader)

        for batch_idx, (img, mask) in enumerate(loop):
            # Force la lecture sur le GPU
            img = img.to(DEVICE)
            mask = mask.to(DEVICE)

            # Calcul de la pr√©diction produite par le mod√®le
            predictions = model(img)

            # Calcul de l'erreur
            loss = loss_fn(predictions, mask)
            
            # Mise √† z√©ro des gradients
            optimizer.zero_grad()
            
            # R√©tropropagation
            loss.backward()

            # Mise √† jour des poids
            optimizer.step()

        # Affichage Loss
        print(f"√âpoque {epoch+1}/{NUM_EPOCHS} : Loss = {loss.item():.4f}")
        loss_history.append(loss.item())

    # Sauvegarde des poids
    torch.save(model.state_dict(), "mon_UNET.pth")

    # Cr√©ation du graphique
    plt.figure(figsize=(10, 5))
    plt.plot(loss_history, label='Training Loss')
    plt.title('Progression de l\'entra√Ænement')
    plt.xlabel('√âpoques')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()
    plt.savefig("courbe_loss.png") # On sauvegarde l'image
    print("Graphique sauvegard√© sous 'courbe_loss.png' üìà")
